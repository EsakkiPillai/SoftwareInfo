===================================================================================================================================================
WorkFlow with fork 
sqoop orders
sqoop order_items 
hive table creation 
sqoop orders and Order items export in parallel
shell 
------------------------------------------------------------------
<workflow-app xmlns="uri:oozie:workflow:0.4" name="daily_revenue-wf">
<start to='ForkNode' />
	<fork name="ForkNode">
		<path start="sqoop-Orders"/>
		<path start="sqoop-order_items"/>
	</fork>
        <action name="sqoop-Orders">
                <sqoop xmlns="uri:oozie:sqoop-action:0.2">
                                <job-tracker>${jobTracker}</job-tracker>
                                <name-node>${nameNode}</name-node>
                                <configuration>
                                        <property>
                                                <name>mapred.job.queue.name</name>
                                                <value>${queueName}</value>
                                        </property>
                                </configuration>
                                <command>import --connect jdbc:mysql://nn01.itversity.com/retail_db --username retail_dba --password itversity --table orders -m 3 --split-by order_id --target-dir  /user/esakkipillai/hadoop/oozie_demo/dailyrevfork/retail_db/orders</command>
                        </sqoop>
                        <ok to="join-node"/>
                        <error to="sqoop-load-fail"/>
                </action>
        <action name="sqoop-order_items">
                <sqoop xmlns="uri:oozie:sqoop-action:0.2">
                                <job-tracker>${jobTracker}</job-tracker>
                                <name-node>${nameNode}</name-node>
                                <configuration>
                                        <property>
                                                <name>mapred.job.queue.name</name>
                                                <value>${queueName}</value>
                                        </property>
                                </configuration>
                                <command>import --connect jdbc:mysql://nn01.itversity.com/retail_db --username retail_dba --password itversity --table order_items -m 3 --split-by order_item_order_id --target-dir  /user/esakkipillai/hadoop/oozie_demo/dailyrevfork/retail_db/order_items</command>
                        </sqoop>
                        <ok to="join-node"/>
                        <error to="sqoop-load-fail"/>
         </action>
		<join name="join-node" to="hive-Table_Ctreation"/>
        <action name="hive-Table_Ctreation">
                <hive xmlns="uri:oozie:hive-action:0.2">
        <job-tracker>${jobTracker}</job-tracker>
        <name-node>${nameNode}</name-node>
        <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>              
            </configuration>
                        <script>Hive_Create_Table.hql</script>
        </hive>
        <ok to="ForkexportNode"/>
        <error to="fail"/>
        </action>		
	<fork name="ForkexportNode">
		<path start="sqoop-export-Orders"/>
		<path start="sqoop-export-order_items"/>
	</fork>
	<action name="sqoop-export-Orders">
        <sqoop xmlns="uri:oozie:sqoop-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <command>export --connect jdbc:mysql://nn01.itversity.com/retail_export --username retail_dba --password itversity --table orders_oozexpo -m 3  --export-dir  /user/esakkipillai/hadoop/oozie_demo/dailyrevfork/retail_db/orders</command>
        </sqoop>
        <ok to="join-mysql-node"/>
        <error to="sqoop-load-fail"/>
    </action>
	<action name="sqoop-export-order_items">
        <sqoop xmlns="uri:oozie:sqoop-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <command>export --connect jdbc:mysql://nn01.itversity.com/retail_export --username retail_dba --password itversity --table order_items_oozexpo -m 3 --export-dir  /user/esakkipillai/hadoop/oozie_demo/dailyrevfork/retail_db/order_items</command>
        </sqoop>
        <ok to="join-mysql-node"/>
        <error to="sqoop-load-fail"/>
    </action>
	<join name="join-mysql-node" to="shell"/>
	<action name="shell">
		<shell xmlns="uri:oozie:shell-action:0.1">
			<job-tracker>${jobTracker}</job-tracker>
			<name-node>${nameNode}</name-node>
			<exec>run.sh</exec>
			<file>/user/esakkipillai/hadoop/oozie_demo/dailyrevfork/run.sh</file>
			<capture-output/>
		</shell>
    
		<ok to="end"/>
		<error to="fail"/>
	</action>
        <kill name="sqoop-load-fail">
                        <message>Sqoop export failed please check Dude, error message[${wf:errorMessage(wf:lastErrorNode())}]</message>
         </kill>

        <kill name="fail">
        <message>Hive failed, error message[${wf:errorMessage(wf:lastErrorNode())}]</message>
    </kill>

<end name="end"/>

</workflow-app>

==============================================================================================================================================================================================================================================================================================================

MY SQL 
--------

mysql -u retail_dba -h nn01.itversity.com -p 

TRUNCATE TABLE orders_join_oozexp;

ALTER TABLE order_items_oozexp 
DROP FOREIGN KEY order_id;



create table orders_oozexpo (
order_id   INT  primary key ,       
order_date  datetime  ,      
order_customer_id INT  ,
order_status      VARCHAR(45)
)


create table order_items_oozexpo (
order_item_id int primary key,
order_item_order_id int ,
order_item_product_id int,
order_item_quantity int,
order_item_subtotal float,
order_item_price float
)



=============================================================================================================

hadoop fs -ls /user/esakkipillai/hadoop/oozie_demo/dailyrevfork
hadoop fs -rm -r  /user/esakkipillai/hadoop/oozie_demo/dailyrevfork/retail_db/*

hadoop fs -rm -r  /user/esakkipillai/hadoop/oozie_demo/dailyrevfork/*
hadoop fs -mkdir  /user/esakkipillai/hadoop/oozie_demo/dailyrevfork/retail_db

hadoop fs -put   /home/esakkipillai/hadoop/oozie_demo/dailyrevfork/Hive_Create_Table.hql /user/esakkipillai/hadoop/oozie_demo/dailyrevfork/



oozie job -oozie http://nn01.itversity.com:11000/oozie -config /home/esakkipillai/hadoop/oozie_demo/dailyrevfork/job.properties -run

oozie job -oozie http://nn01.itversity.com:11000/oozie -info 

hadoop fs -rm -r  /user/esakkipillai/hadoop/oozie_demo/dailyrevfork/retail_db/*
hadoop fs -rm -r /user/esakkipillai/hadoop/oozie_demo/dailyrevfork/Hive_Create_Table.hql
hadoop fs -put   /home/esakkipillai/hadoop/oozie_demo/dailyrevfork/* /user/esakkipillai/hadoop/oozie_demo/dailyrevfork/

===========================================================================================================================================
use esak07;
drop table orders;
drop table order_items;

create external table orders (
order_id int,
order_date string,
order_customer_id int,
order_status string
) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' 
STORED AS TEXTFILE
location '/user/esakkipillai/hadoop/oozie_demo/dailyrevfork/retail_db/orders';

create external table order_items (
order_item_id int,
order_item_order_id int,
order_item_product_id int,
order_item_quantity int,
order_item_subtotal float,
order_item_price float 
) row format delimited fields terminated by ','
location '/user/esakkipillai/hadoop/oozie_demo/dailyrevfork/retail_db/order_items';

create  external table orders_join_new(
order_item_order_id  int, 
order_customer_id int, 
order_date string, 
order_item_product_id int, 
order_item_subtotal float,
order_status string
)ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
location '/user/esakkipillai/hadoop/oozie_demo/dailyrevfork/retail_db/orders_join' ;

INSERT  INTO TABLE esak07.orders_join_new
select oi.order_item_order_id , o.order_customer_id, o.order_date, oi.order_item_product_id , oi.order_item_subtotal ,o.order_status
from orders o join order_items oi 
on o.order_id = oi.order_item_id ;

====================================================================================================================================================
use esak07;

CTRL A character is represented by --fields-terminated-by '\^A'



==================================================================================================================================================






