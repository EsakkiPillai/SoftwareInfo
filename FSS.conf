### The Following Configuration is used for the Flume spark Hdfs 
# Describe the Agent Here
ag1.sources = execsources 
ag1.sinks = hdfssink sparksink
ag1.channels = sparkchannel hdfschannel

#Desccribe the Source 
ag1.sources.execsources.type = exec
ag1.sources.execsources.command = tail -F /opt/gen_logs/logs/access.log

#Describe the Hdfssink
ag1.sinks.hdfssink.type= hdfs
ag1.sinks.hdfssink.hdfs.path= /user/esakkipillai/flumeKafka
ag1.sinks.hdfssink.hdfs.filePrefix = execsource-%d-%m-%y
ag1.sinks.hdfssink.hdfs.fileSuffix=.txt
ag1.sinks.hdfssink.hdfs.useLocalTimeStamp=true
ag1.sinks.hdfssink.hdfs.rollInterval = 120

#Describe the sparksink 
ag1.sinks.sparksink.type = org.apache.spark.streaming.flume.sink.SparkSink
ag1.sinks.sparksink.hostname = gw01.itversity.com
ag1.sinks.sparksink.port = 44444


#Describe the File Channel 
ag1.channels.hdfschannel.type = FILE

#Describe the memory Channel 
ag1.channels.sparkchannel.type = memory
ag1.channels.sparkchannel.transactionCapacity=100
ag1.channels.sparkchannel.capacity=1000

# Bind the Components
ag1.sources.execsources.channels=sparkchannel hdfschannel
ag1.sinks.hdfssink.channel = hdfschannel
ag1.sinks.sparksink.channel = sparkchannel
